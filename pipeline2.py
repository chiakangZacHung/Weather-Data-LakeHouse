# -*- coding: utf-8 -*-
"""Pipeline2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AO5BuKST3rcAyl8ouF3WTuFMQg0_lXM4
"""

#create session
import pyspark
from delta import *

builder = pyspark.sql.SparkSession.builder.appName("MyApp") \
.config("spark.jars.packages", "io.delta:delta-core_2.13:2.1.0") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")

spark = configure_spark_with_delta_pip(builder).getOrCreate()

def getLatestFile(pathname):
  import glob
  import os
  list_of_files = glob.glob(pathname) # * means all if need specific format then *.csv
  import builtins
  return builtins.max(list_of_files,key=os.path.getmtime)

#directories
import sys
input_directory = sys.argv[1]
output_directory= sys.argv[2]

from pyspark.sql import functions as F
import time
from pyspark.sql.functions import *
# ts stores the time in seconds
import datetime;
ct = datetime.datetime.today()
str_date_time = ct.strftime("%d_%m_%Y")
latest_file=getLatestFile(input_directory+'/*')

device_info=spark.read.option("header",True).csv(latest_file)
device_info.write \
  .format("delta") \
  .mode("append") \
  .save(output_directory+str_date_time)