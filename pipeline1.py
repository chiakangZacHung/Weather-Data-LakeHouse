# -*- coding: utf-8 -*-
"""Pipeline1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UqqwIvY_AARY2SDXbrSQkSDz1_-Mhu8t
"""

#define directories
import sys
input_directory = sys.argv[1]
output_directory= sys.argv[2]

#get latest file in directory
def getLatestFile(pathname):
  import glob
  import os
  list_of_files = glob.glob(pathname) # * means all if need specific format then *.csv
  import builtins
  return builtins.max(list_of_files,key=os.path.getmtime)

#create session
import pyspark
from delta import *

builder = pyspark.sql.SparkSession.builder.appName("MyApp") \
.config("spark.jars.packages", "io.delta:delta-core_2.13:2.1.0") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")

spark = configure_spark_with_delta_pip(builder).getOrCreate()

#write device data file using timestamp
from pyspark.sql import functions as F
import time
from pyspark.sql.functions import *
# ts stores the time in seconds
import datetime;
# read from file
latest_file=getLatestFile(input_directory+'/*')
df_input = spark.read.json(latest_file)
ct = datetime.datetime.today()
str_date_time = ct.strftime("%d_%m_%Y")

df_input=df_input.withColumn("arrival_time",  F.current_timestamp())\
.withColumn("arrival_date", F.current_date())
df_input.write \
  .format("delta") \
  .partitionBy("arrival_date") \
  .mode("append") \
  .save(output_directory+str_date_time)